# American Sign Language Recognition
A Deep Learning-Based Algorithm for American Sign Language Recognition

## INTRODUCTION        
● Speech-impaired individuals often rely on hand signs and gestures, or sign language, to communicate. People who are not
familiar with sign language may find it difficult to understand these signs and gestures. This creates a communication barrier.            
● In the US, approximately around 500,000 people use American sign language (ASL) as primary means of communication.          
● With advancements in technology, particularly in the field of machine learning and artificial intelligence, it’s now possible to
develop a system that can recognize sign language. Such a system could translate sign language breaking down the
communication barrier, promoting inclusivity and accessibility and making interactions smoother and more natural.              
● Our project aims to develop a system that can classify sign language symbols using deep learning techniques. This system will
be able to recognize different signs and gestures and translate them into understandable language.            

## DATA
● The data set is a collection of images from the American Sign Language.        
● There are 36 classes which include 0-9 and A-Z alphabets.

![image](https://github.com/user-attachments/assets/9f0fe42d-810c-4330-9933-a60dbbed49b8)

View below document for the Results:
[MK-ASL_recognition.pdf](https://github.com/user-attachments/files/17612813/MK-ASL_recognition.pdf)

